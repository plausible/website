---
layout: post
title: How to A/B test your website?
description: c
slug: ab-testing
date: 2025-06-21T06:38:02.782Z
author: hricha-shandily
---
User behaviour keeps evolving. This means many things that used to resonate five or ten years ago, won’t now. For instance, a few years ago, it was normal to visit homepages of news outlets and now most of us prefer algorithm-curated, bite-sized news over full articles.
Earlier, it was normal to browse info-heavy, desktop-first websites by clicking through menus and pages. Clicking through multiple pages was expected. Now? Users primarily use mobile, expecting fast, thumb-friendly designs, and preferring clean layouts with a clear, singular purpose per page.
Such evolving behaviours usually leave a lot of room to experiment for brands in terms of what could psychologically and behaviourally resonate with the customers of today.

“Which messaging would resonate best with my audiences? A short one telling about my product’s benefits or a longer one talking about its outcomes?”
“Does including customer logos on the homepage increase sign ups? Or a minimal, non-pushy design without the logos assumes more trust?”
“Does a strikethrough pricing with a promotional 20% off convert better than a simply written amount?”
“Does a sign-up button placed on the top-right make more sense for my audience, or one placed in the center of the landing page encourages sign up?”
“Is a 4-column pricing layout clearer than a 4-boxed pricing layout?”

…and so on. These are questions that a website designer, marketer, content-writer, business owner – whoever working on the website can wonder about. One way to find a definitive answer to such questions is to run scientific experiments and settle the debate with what the actual end users like.

Think of A/B testing as a way to engineer the closest version possible to that ideal webpage / website that hits the bulls eye –– aligning with customer behaviours and best user experience.

1. Ordered list
   {:toc}

## What is A/B testing?

The whole idea of an A/B test is to run a controlled experiment on a random set of audience by showing them two (or more) versions of the same element of a website (a homepage’s heading, placement of a CTA button, colour of the website, etc.) and deciding what works best to encourage actions like sign ups, revenue, subscriptions, wishlisting, or whatever it is that matters to you as a website owner.

A/B testing is also called split testing or bucket testing. Literally, it means that you split the current version of the website asset to be tested into 2 versions, symbolized by “A” and “B.” Everything else is kept the same, while either of those 2 versions are shown randomly to the people visiting the website.

You run this experiment for some time (like a week or a quarter) depending on the nature and scale of the experiment, and see which of the versions win. This is a scientific and data-backed way of picking clearly what works and not relying on guesswork or intuition.

Say, you sell cotton socks through an e-commerce site and it being summer, you’re running a promotional campaign. You design a web page for the same and want to see which promotional copy is more successful in driving sales through that web page:

**Variant A**: “Beat the heat! Get breathable cotton socks at 20% off.”

**Variant B**: “Summer Sale! Stay cool with 20% off on all cotton socks.”

You split the traffic evenly—50% of visitors see Variant A, and 50% see Variant B. At the end of the experimentation period, you track which group led to more purchases. If Variant B results in more people buying socks, you can conclude that its messaging is more effective.

Another common A/B test, especially back in the day, for landing pages used to be testing the right-left layout, i.e., whether it’s better to show the image on the right of the main messaging or to the left of it. Something like this: